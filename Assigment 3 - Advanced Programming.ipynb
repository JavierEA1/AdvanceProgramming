{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment Number 3 - Advanced Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Members: Javier Esteban Aragoneses - Mauricio Marcos Fajgenbaun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let´s call all the libraries we will need for this assigment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.validation import check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let´s download the dataset given by the professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=pd.read_pickle('desktop/wind_pickle.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will remove the columns: \"steps\",\"months\",\"day\",\"hour\" from our dataset. And then we make sure, that we haev done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['energy', 'year', 'p54.162.1', 'p54.162.2', 'p54.162.3', 'p54.162.4',\n",
       "       'p54.162.5', 'p54.162.6', 'p54.162.7', 'p54.162.8',\n",
       "       ...\n",
       "       'v100.16', 'v100.17', 'v100.18', 'v100.19', 'v100.20', 'v100.21',\n",
       "       'v100.22', 'v100.23', 'v100.24', 'v100.25'],\n",
       "      dtype='object', length=552)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.drop(['steps','month','day','hour'],axis='columns', inplace=True)\n",
    "datos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we set a random seed to make our assigment reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_NIA = 100445061\n",
    "np.random.seed(100445061)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to replace some values with: Nan. As \"year\" will be used to partitionate the data, and \"energy\" is our response variable, we will leave them aside for this step. Then, we select, at random, 10% of the columns and, again, select 5% of the data inside those columns and replaced them with Nan values. This way, there are 5% of data (from within that 10% column selection) that will take value Nan, but not necesarily 5% in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2 = datos.drop(['year','energy'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2 = datos.sample(frac=0.10,axis='columns')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mat = np.random.random(datos2.shape)<0.05\n",
    "nan_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_NaN = datos2.mask(nan_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datos_NaN.columns:\n",
    "    datos[col]=datos_NaN[col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing this, we save this in a new file called \"data.pickle\", as this is going to be the dataset we will use.\n",
    "Please note, that both \"year\" and \"energy\" are still in the dataset: as they are fundamental for our research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.to_pickle('data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the new file, we divide the dataset in three: training set, validation set, and testing set. We do so, by partitioning through our variable year: 2005-2006, 2007-2008 and 2009-2010. After doing this we drop our variable year, in order to transform the dataframe into a numpy matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_data=data.loc[(data.year==2005)|(data.year==2006)]\n",
    "train_data.drop(['year'],axis='columns', inplace=True)\n",
    "#validation\n",
    "validation_data=data.loc[(data.year==2007)|(data.year==2008)]\n",
    "validation_data.drop(['year'],axis='columns', inplace=True)\n",
    "\n",
    "#test\n",
    "test_data=data.loc[(data.year==2009)|(data.year==2010)]\n",
    "test_data.drop(['year'],axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform it to a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_y=train_data['energy'].values\n",
    "train_x=train_data.loc[:,train_data.columns !='energy'].values\n",
    "\n",
    "#validation\n",
    "validation_y=validation_data['energy'].values\n",
    "validation_x=validation_data.loc[:,validation_data.columns !='energy'].values\n",
    "\n",
    "#test\n",
    "test_y=test_data['energy'].values\n",
    "test_x=test_data.loc[:,test_data.columns !='energy'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will first build three preditive models: Knn, Regression Trees and SVMs with default hiper parameters.\n",
    "For imputation, we will use strategy \"median\", just to try it. After doing the three models, we will check the \"mean absolute error\" as our metric for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation=SimpleImputer(strategy='median')\n",
    "scale=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=Pipeline([\n",
    "    ('imputation',imputation),\n",
    "    ('scale',scale),\n",
    "    ('model', KNeighborsRegressor()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=Pipeline([\n",
    "    ('imputation',imputation),\n",
    "    ('scale',scale),\n",
    "    ('model', SVR()) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=Pipeline([\n",
    "    ('imputation',imputation),\n",
    "    ('model', DecisionTreeRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputation', SimpleImputer(strategy='median')),\n",
       "                ('scale', MinMaxScaler()), ('model', KNeighborsRegressor())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_predict_knn=knn.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365.1681279620853\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test_y,test_y_predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517.5868734870595\n"
     ]
    }
   ],
   "source": [
    "svm.fit(train_x,train_y)\n",
    "test_y_predict_svm=svm.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399.033327014218\n"
     ]
    }
   ],
   "source": [
    "tree.fit(train_x,train_y)\n",
    "test_y_predict_tree=tree.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline1</th>\n",
       "      <th>pipeline2</th>\n",
       "      <th>pipeline3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.168</td>\n",
       "      <td>517.587</td>\n",
       "      <td>399.033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pipeline1 pipeline2 pipeline3\n",
       "0       Knn       SVM      Tree\n",
       "1   365.168   517.587   399.033"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores={'pipeline1':['Knn',365.1681],'pipeline2':['SVM',517.5868],'pipeline3':['Tree',399.03332]}\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, according to the different mean absolute error, our best model is the Knn, followed by the Tree Regression and lastly our Support Vector Machine model.\n",
    "Then, we will do something similar, but doing hyper parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing this, we follow the instructions and decide to use  PredefinedSplit with no\n",
    "shuffling for the hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit,RandomizedSearchCV\n",
    "validation_indices = np.zeros(validation_x.shape[0])\n",
    "validation_indices[:round(2/3*validation_x.shape[0])] = -1\n",
    "tr_val_partition = PredefinedSplit(validation_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knn with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Knn, we will try to tune (with RandomizedSearchCV) the following 4 parameters:\n",
    "\n",
    "a) Number of neighbours: this is the number of neighbors picked.\n",
    "\n",
    "b) Leaf size: This can affect the speed of the construction and query, as well as the memory required to store the tree.\n",
    "\n",
    "c) Algorithm: this is just the algorithm that will be used to compute the model. It can be: \"auto\", \"ball_tree\", \"kd_tree\", \"brute\".\n",
    "\n",
    "d) Weights: this is the function of weight that our model will use. We will either chose uniform weights or the inverse of the distance.\n",
    "\n",
    "e) Imputing strategy: either using the mean or the median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'model__n_neighbors':np.arange(2,15,1),\n",
    "    'model__leaf_size':np.arange(25,35,1),\n",
    "    'model__algorithm':['auto','ball_tree','kd_tree','brute'],\n",
    "    'model__weights':['uniform','distance'],\n",
    "    'impute__strategy':['mean','median'],\n",
    "}\n",
    "knn = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', scale),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "knn_2 = RandomizedSearchCV(estimator=knn,\n",
    "                            param_distributions=knn_params,\n",
    "                            n_iter=15,\n",
    "                            cv=tr_val_partition,\n",
    "                            scoring='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct our Support Vector Machine model, with hyper parameter tuning. We will tune the following parameters:\n",
    "\n",
    "degree: degree of th epolynomial Kernel function.\n",
    "\n",
    "gamma: is a Kernel coefficient, and can take values \"scale\" (1 / (Nº of features * X.var()) or \"auto\" (1/Nº of features).\n",
    "\n",
    "shrinking: wether to use the shrinking euristic or not: true or false.\n",
    "\n",
    "C: this parameter talks about the regularization parameter: and it is inversely proportional to C.\n",
    "\n",
    "Imputation strategy: either using mean or median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "svm_params = {\n",
    "    'model__degree':np.arange(2,15,1),\n",
    "    'model__gamma':list({'scale','auto'}.union(set(np.logspace(-2, 10, 13)))),\n",
    "    'model__shrinking':[True, False],\n",
    "    'model__C':np.logspace(1, 10, 13),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR())])\n",
    "\n",
    "\n",
    "svm_2 = RandomizedSearchCV(estimator=svm,\n",
    "                            param_distributions=svm_params,\n",
    "                            n_iter=15,\n",
    "                            cv=tr_val_partition,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let´s do our Decition Tree Regressor model, with hyper parameter tuning. We will tune the following parameters:\n",
    "\n",
    "a) criterion:\n",
    "\n",
    "b) splitter:\n",
    "\n",
    "c) max_depth:\n",
    "\n",
    "d) min_samples_split:\n",
    "\n",
    "e) min_samples_leaf:\n",
    "\n",
    "f) min_weight_fraction_leaf:\n",
    "\n",
    "g) max_feature:\n",
    "\n",
    "h) impuete strategy: either mean or median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree\n",
    "tree_params = {\n",
    "    'model__criterion':['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "    'model__splitter':['best','random'],\n",
    "    'model__max_depth':np.arange(2,15,1),\n",
    "    'model__min_samples_split':np.arange(2,15,1),\n",
    "    'model__min_samples_leaf':np.arange(1,15,1),\n",
    "    'model__min_weight_fraction_leaf':np.linspace(0, 0.5, 25),\n",
    "    'model__max_features':['auto','sqrt','log2'],\n",
    "    'impute__strategy':['mean','median'],\n",
    "}\n",
    "\n",
    "tree = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('model', DecisionTreeRegressor())])\n",
    "\n",
    "tree_2 = RandomizedSearchCV(estimator=tree,\n",
    "                            param_distributions=tree_params,\n",
    "                            n_iter=15,\n",
    "                            cv=tr_val_partition,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let´s train and test our new three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                                             ('scale', MinMaxScaler()),\n",
       "                                             ('model', KNeighborsRegressor())]),\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'impute__strategy': ['mean', 'median'],\n",
       "                                        'model__algorithm': ['auto',\n",
       "                                                             'ball_tree',\n",
       "                                                             'kd_tree',\n",
       "                                                             'brute'],\n",
       "                                        'model__leaf_size': array([25, 26, 27, 28, 29, 30, 31, 32, 33, 34]),\n",
       "                                        'model__n_neighbors': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'model__weights': ['uniform',\n",
       "                                                           'distance']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_2.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358.5663611316951\n"
     ]
    }
   ],
   "source": [
    "test_y_predict_knn_2=knn_2.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_knn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                                             ('scaler', MinMaxScaler()),\n",
       "                                             ('model', SVR())]),\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'impute__strategy': ['mean', 'median'],\n",
       "                                        'model__C': array([1.00000000e+01, 5.62341325e+01, 3.16227766e+02, 1.77827941e+03,\n",
       "       1.00000000e+04, 5.62341325e+04, 3.162...27941e+06,\n",
       "       1.00000000e+07, 5.62341325e+07, 3.16227766e+08, 1.77827941e+09,\n",
       "       1.00000000e+10]),\n",
       "                                        'model__degree': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'model__gamma': [0.1, 1.0, 100000.0,\n",
       "                                                         1000000.0, 100.0,\n",
       "                                                         10000000.0,\n",
       "                                                         100000000.0,\n",
       "                                                         1000000000.0, 1000.0,\n",
       "                                                         10000000000.0, 'auto',\n",
       "                                                         10.0, 0.01, 10000.0,\n",
       "                                                         'scale'],\n",
       "                                        'model__shrinking': [True, False]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_2.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430.90390422116053\n"
     ]
    }
   ],
   "source": [
    "test_y_predict_svm_2=svm_2.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_svm_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'poisson'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'poisson'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                                             ('model',\n",
       "                                              DecisionTreeRegressor())]),\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'impute__strategy': ['mean', 'median'],\n",
       "                                        'model__criterion': ['mse',\n",
       "                                                             'friedman_mse',\n",
       "                                                             'mae', 'poisson'],\n",
       "                                        'model__max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'mod...\n",
       "                                        'model__min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'model__min_weight_fraction_leaf': array([0.        , 0.02083333, 0.04166667, 0.0625    , 0.08333333,\n",
       "       0.10416667, 0.125     , 0.14583333, 0.16666667, 0.1875    ,\n",
       "       0.20833333, 0.22916667, 0.25      , 0.27083333, 0.29166667,\n",
       "       0.3125    , 0.33333333, 0.35416667, 0.375     , 0.39583333,\n",
       "       0.41666667, 0.4375    , 0.45833333, 0.47916667, 0.5       ]),\n",
       "                                        'model__splitter': ['best', 'random']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344.14989425692903\n"
     ]
    }
   ],
   "source": [
    "test_y_predict_tree_2=tree_2.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_tree_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline1</th>\n",
       "      <th>pipeline2</th>\n",
       "      <th>pipeline3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358.56</td>\n",
       "      <td>430.9</td>\n",
       "      <td>344.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pipeline1 pipeline2 pipeline3\n",
       "0       Knn       SVM      Tree\n",
       "1    358.56     430.9    344.15"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores={'pipeline1':['Knn',358.56],'pipeline2':['SVM',430.9],'pipeline3':['Tree',344.15]}\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let´s just use our Knn model, and do Feature Selection, Principal Component Analysis. First, only FS, then only PCA and lastly both of them (the three times, in our Knn model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params_3 = {\n",
    "    'model__n_neighbors':np.arange(2,15,1),\n",
    "    'model__leaf_size':[30],\n",
    "    'model__algorithm':['auto'],\n",
    "    'model__weights':['uniform'],\n",
    "    'select__k':list(set(np.arange(2,100,1)).union({'all'})),\n",
    "    'impute__strategy':['mean']\n",
    "}\n",
    "knn=Pipeline([\n",
    "    ('impute',SimpleImputer()),\n",
    "    ('scale', scale),\n",
    "    ('select',SelectKBest()),\n",
    "    ('model', KNeighborsRegressor())\n",
    "\n",
    "])\n",
    "knn_3 = RandomizedSearchCV(estimator=knn,\n",
    "                            param_distributions=knn_params_3,\n",
    "                            n_iter=15,\n",
    "                            cv=tr_val_partition,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                                             ('scale', MinMaxScaler()),\n",
       "                                             ('select', SelectKBest()),\n",
       "                                             ('model', KNeighborsRegressor())]),\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'impute__strategy': ['mean'],\n",
       "                                        'model__algorithm': ['auto'],\n",
       "                                        'model__leaf_size': [30],\n",
       "                                        'model__n_neighbors': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'model__weights': ['uniform'],\n",
       "                                        'select__k': [2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, 31, ...]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_3.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336.91418088467617\n"
     ]
    }
   ],
   "source": [
    "test_y_predict_knn_3=knn_3.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_knn_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn_params_4 = {\n",
    "    'model__n_neighbors':np.arange(2,15,1),\n",
    "    'model__leaf_size':[30],\n",
    "    'model__algorithm':['auto'],\n",
    "    'model__weights':['uniform'],\n",
    "    'pca__n_components':list(set(np.arange(2,100,1)).union({'all','mle'})),\n",
    "    'impute__strategy':['mean']\n",
    "\n",
    "}\n",
    "knn=Pipeline([\n",
    "    ('impute',SimpleImputer()),\n",
    "    ('scale', scale),\n",
    "    ('pca',PCA()),\n",
    "    ('model', KNeighborsRegressor()) \n",
    "])\n",
    "knn_4 = RandomizedSearchCV(estimator=knn,\n",
    "                            param_distributions=knn_params_4,\n",
    "                            n_iter=15,\n",
    "                            cv=tr_val_partition,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                                             ('scale', MinMaxScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('model', KNeighborsRegressor())]),\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'impute__strategy': ['mean'],\n",
       "                                        'model__algorithm': ['auto'],\n",
       "                                        'model__leaf_size': [30],\n",
       "                                        'model__n_neighbors': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'model__weights': ['uniform'],\n",
       "                                        'pca__n_components': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_4.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360.1497227488152\n"
     ]
    }
   ],
   "source": [
    "test_y_predict_knn_4=knn_4.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_knn_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=Pipeline([\n",
    "    ('impute',SimpleImputer()),\n",
    "    ('scale', scale),\n",
    "    (\"pca\", PCA()),\n",
    "    ('select',SelectKBest()),\n",
    "    ('model', KNeighborsRegressor()) \n",
    "    \n",
    "])\n",
    "knn_params_5 = {\n",
    "    'model__n_neighbors':np.arange(2,15,1),\n",
    "    'model__leaf_size':np.arange(25,35,1),\n",
    "    'model__algorithm':['auto'],\n",
    "    'model__weights':['uniform'],\n",
    "    'pca__n_components':list(set(np.arange(2,20,1)).union({'all','mle'})),\n",
    "    'select__k':list(set(np.arange(2,30,1)).union({'all'})),\n",
    "    'impute__strategy':['mean']\n",
    "\n",
    "}\n",
    "knn_5 = RandomizedSearchCV(estimator=knn,\n",
    "                            param_distributions=knn_params_5,\n",
    "                            n_iter=15,\n",
    "                            cv=tr_val_partition,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 18; got 20. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 6; got 15. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 11; got 29. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 9; got 12. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 19; got 28. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 7; got 29. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 6; got 18. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 6; got 20. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 9; got 28. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/mauriciomarcos/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 8; got 28. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                                             ('scale', MinMaxScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('select', SelectKBest()),\n",
       "                                             ('model', KNeighborsRegressor())]),\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'impute__strategy': ['mean'],\n",
       "                                        'model__algorithm': ['auto'],\n",
       "                                        'model__leaf_size': array([25, 26, 27, 28, 29, 30, 31, 32, 33, 34]),\n",
       "                                        'model__n_neighbors': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'model__weights': ['uniform'],\n",
       "                                        'pca__n_components': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 'mle',\n",
       "                                                              'all'],\n",
       "                                        'select__k': [2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 'all']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_5.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451.99043917851503\n"
     ]
    }
   ],
   "source": [
    "test_y_predict_knn_5=knn_5.predict(test_x)\n",
    "print(mean_absolute_error(test_y,test_y_predict_knn_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={'pipeline1':['Fselection',336.91],'pipeline2':['PCA',360.15],'pipeline3':['Both',451.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline1</th>\n",
       "      <th>pipeline2</th>\n",
       "      <th>pipeline3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fselection</td>\n",
       "      <td>PCA</td>\n",
       "      <td>Both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336.91</td>\n",
       "      <td>360.15</td>\n",
       "      <td>451.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pipeline1 pipeline2 pipeline3\n",
       "0  Fselection       PCA      Both\n",
       "1      336.91    360.15     451.9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the results above, our best model (the one with the lowet mean absolute error) is our Knn with Feature Selection, followed by our Knn with Principal Component Analysis and lastly our Knn with both.\n",
    "When comparing with our Knn from the previous section, we can see that we got a better one now when using Feature Selection: we reduce the mean absolute error from 358.6 to 336.91. This means our model will be more powerful, or at least it will commit less errors. As we are using absolute mean error, and not squared mean errors, let´s note that we are not penalizing the model for values that fall very far away from the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check what are the features selected from our dataset in this best model. As we know already, we have 25 locations, so every variable is measured in 25 different locations (marked by the number after the dot in each column name\". In other words: \"cape.24\" is measuring \"cape\" in location number 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cape.24', 'cape.25', 'p59.162.1', 'p59.162.2', 'p59.162.3',\n",
       "       'p59.162.4', 'p59.162.5', 'p59.162.6', 'p59.162.7', 'p59.162.8',\n",
       "       'p59.162.9', 'p59.162.10', 'p59.162.11', 'p59.162.12', 'p59.162.13',\n",
       "       'p59.162.14', 'p59.162.15', 'p59.162.16', 'p59.162.17', 'p59.162.18',\n",
       "       'p59.162.19', 'p59.162.20', 'p59.162.21', 'p59.162.22', 'p59.162.23',\n",
       "       'u10n.24', 'u10n.25', 'stl3.24', 'stl3.25', 'iews.1', 'iews.2',\n",
       "       'iews.3', 'iews.4', 'iews.5', 'iews.6', 'iews.7', 'iews.8', 'iews.9',\n",
       "       'iews.10', 'iews.11', 'iews.12', 'iews.13', 'iews.14', 'iews.15',\n",
       "       'iews.16', 'iews.17', 'iews.18', 'iews.19', 'iews.20', 'iews.21',\n",
       "       'iews.22', 'iews.23', 'iews.24', 'iews.25', 'inss.1', 'inss.2',\n",
       "       'inss.3', 'inss.4', 'inss.5', 'inss.6', 'inss.7', 'inss.8', 'inss.9',\n",
       "       'inss.10', 'inss.11', 'inss.12', 'inss.13', 'inss.14', 'inss.15',\n",
       "       'inss.16', 'inss.17', 'inss.18', 'inss.19', 'inss.20', 'inss.21',\n",
       "       'inss.22', 'inss.23', 'u100.24', 'u100.25', 'v100.1', 'v100.2',\n",
       "       'v100.3', 'v100.4', 'v100.5', 'v100.6', 'v100.7', 'v100.8', 'v100.10',\n",
       "       'v100.11', 'v100.12', 'v100.13', 'v100.14', 'v100.15', 'v100.16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=knn_3.best_estimator_.named_steps['select'].get_support(indices=True)\n",
    "todas = data.iloc[:,a]\n",
    "todas.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(todas.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model takes 94 features. But we are interested in two things:\n",
    "\n",
    "a) how many times do we take into account location number 13 (Sotavento)?\n",
    "\n",
    "b) What are the locations with higher frequencies: that is, that are taken more into account.\n",
    "\n",
    "We can easily see that Location Number 13 is evaluated 4 times. While there are others such as, location Number 24, that is counted 5 times as well as location number 25; locations between 10-16 are counted 4 times as well as locations between Number 1 and Number 8. Locations between 17-23 were taken into account only 3 times, as well as location Number 9.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
